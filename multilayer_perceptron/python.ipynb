{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perception implemented in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import get_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "words = get_names()\n",
    "print(words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bigram character language model\n",
    "- receives a single character as input; output is the probability distribution of the next character in the sequence\n",
    "- using gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "27\n",
      "{'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "characters = ['.', *sorted({c for w in words for c in w})]\n",
    "print(characters)\n",
    "print(len(characters))\n",
    "index = {\n",
    "    c:i\n",
    "    for i, c in enumerate(characters)\n",
    "}\n",
    "index\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 13 13  1  0 15 12  9 22]\n",
      "[ 5 13 13  1  0 15 12  9 22  9]\n"
     ]
    }
   ],
   "source": [
    "# create the training set of all of the bigrams\n",
    "# x is the input, y is the target (i.e. the next character)\n",
    "x, y = [], []\n",
    "training_data = []\n",
    "for w in words:\n",
    "    chars = ['.',  *w, '.']\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        x.append(index[c1])\n",
    "        y.append(index[c2])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "print(x[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xffff3a548710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode\n",
    "def one_hot_encode(index: int) -> np.array:\n",
    "    \"\"\"Return a one-hot encoded vector of the given index.\"\"\"\n",
    "    vector = np.zeros(len(characters))\n",
    "    vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "x_encoded = np.array([one_hot_encode(i) for i in x])\n",
    "y_encoded = np.array([one_hot_encode(i) for i in y])\n",
    "\n",
    "print(x_encoded[:6])\n",
    "plt.imshow(x_encoded[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 27)\n",
      "(50, 1)\n",
      "(27, 50)\n",
      "(27, 1)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "input_size = len(characters)\n",
    "hidden_size = 50\n",
    "output_size = len(characters)\n",
    "\n",
    "# weights between input and hidden layer\n",
    "W_1 = rng.normal(size=(hidden_size, input_size)) * 0.01\n",
    "# biases of the hidden layer\n",
    "b_1 = np.zeros((hidden_size, 1))\n",
    "W_2 = rng.normal(size=(output_size, hidden_size)) * 0.01\n",
    "b_2 = np.zeros((output_size, 1))\n",
    "\n",
    "print(W_1.shape)\n",
    "print(b_1.shape)\n",
    "print(W_2.shape)\n",
    "print(b_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xffff39f818d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(W_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between \"fully connected\" layers and matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a batch of 32 examples, each with 27 features (one hot encoding of characters).\n"
     ]
    }
   ],
   "source": [
    "x_batch = x_encoded[:32]\n",
    "x_batch.shape\n",
    "y_batch = y_encoded[:32]\n",
    "print(f\"We have a batch of {x_batch.shape[0]} examples, each with {x_batch.shape[1]} features (one hot encoding of characters).\")  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate the \"pre-activation values\" which is a value that connects each neuron to an example in the batch.\n",
    "\n",
    "The `pre-activations` are a matrix of values corresponding to the neurons in the hidden layer (`50`) and the batch size (`32`).\n",
    "\n",
    "The pre-activations are calculated by matrix-multiplying the weights of the input/hidden layer by the batch examples/features and adding the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_activations = ((W_1 @ x_batch.T) + b_1)\n",
    "pre_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot(W, x.T) = dot((neurons, input), (input, batch)) = dot((50, 27), (27, 32))\n"
     ]
    }
   ],
   "source": [
    "print(f\"dot(W, x.T) = dot((neurons, input), (input, batch)) = dot({W_1.shape}, {x_batch.T.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot(W, x.T) = dot((neurons, input), (input, batch)) = dot((50, 27), (27, 32)) = ((50, 32))\n"
     ]
    }
   ],
   "source": [
    "pre_activations_hidden = np.dot(W_1, x_batch.T)\n",
    "assert (pre_activations == pre_activations_hidden).all()  # biases are all zeros at this point\n",
    "print(f\"dot(W, x.T) = dot((neurons, input), (input, batch)) = dot({W_1.shape}, {x_batch.T.shape}) = ({pre_activations_hidden.shape})\")  # noqa\n",
    "assert (pre_activations_hidden == W_1 @ x_batch.T).all()\n",
    "# np.dot(W1, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is calculated by taking the first row of the first matrix and the first column of the second matrix and doing a dot product (multiplying all corresponding elements together and then summing across all results), and repeating for all row/column combinations of the first and second matrix respectively.\n",
    "\n",
    "However, in order to do the matrix multiplication with our weight matrix and batch matrix, we have to transpose the batch matrix.\n",
    "\n",
    "We start with these dimensions `(neurons x input_size) @ (batch_size x input_size)`\n",
    "\n",
    "But we need `(neurons x input_size) @ (input_size x batch_size)`\n",
    "\n",
    "And so we take the first row of the weight matrix and the first column of the transposed batch matrix and do a dot product. But the `first column of the transposed batch matrix` is the same as the first row of the non-transposed batch matrix. So really, each value in the pre-activation matrix is the dot product of the connections of a particular neuron (e.g. the first row in weights matrix is the first neuron) to the inputs of a particular example (e.g. first row in batch matrix) resulting an a matrix that has 50 rows corresponding to the the number of neurons and 32 columns corresponding to each of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row of weights, and first column of transposed input\n",
    "w_row = W_1[0, :]\n",
    "xt_column = x_batch.T[:, 0]\n",
    "w_row.shape, xt_column.shape\n",
    "# dot product is just the sum of the element-wise product\n",
    "assert np.dot(w_row, xt_column) == (w_row * xt_column).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but the first column of transposed input is just the first row of the input (non-transposed)\n",
    "for r in range(len(x_batch)):\n",
    "    assert (x_batch.T[:, r] == x_batch[r, :]).all()\n",
    "\n",
    "assert np.dot(w_row, xt_column) == np.dot(w_row, x_batch[0, :])\n",
    "# and so below, we don't need to transpose the input and we can just use the dot product\n",
    "# for each row (i.e. nueron) of the weights and each row (example) of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 32)\n"
     ]
    }
   ],
   "source": [
    "# manual dot product i.e. matrix multiplication\n",
    "# matrix multiplication is the dot product of the rows of the first matrix with the columns of the\n",
    "# second matrix\n",
    "assert W_1.shape[1] == x_batch.T.shape[0]\n",
    "# the result will have the same number of rows as the first matrix and the same number of columns\n",
    "pre_activations_manual = np.zeros((W_1.shape[0], x_batch.shape[0]))\n",
    "for i in range(W_1.shape[0]):\n",
    "    for j in range(x_batch.shape[0]):\n",
    "        pre_activations_manual[i, j] = np.dot(W_1[i], x_batch[j])\n",
    "\n",
    "print(pre_activations_manual.shape)\n",
    "assert (pre_activations_manual == pre_activations_hidden).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and so the first element in the pre-activations is the dot product of the first row (neuron) of the\n",
    "# weights and the first row (example) of the input (we haven't included the bias yet)\n",
    "# in other words, the first neuron is connected to each of the inputs (27) with a weight, which is\n",
    "# why our weights matrix has 27 columns. Each column is a weight for each input. The matrix\n",
    "# connects all of the inputs to all of the neurons. The dot product of the first row of the weights\n",
    "# and the first row of the input is the sum of the element-wise product of the two vectors. This\n",
    "# is the pre-activation of the first neuron for the first example. There are 50 neurons and 32 examples\n",
    "# so the pre-activations matrix is 50 x 32\n",
    "assert pre_activations_hidden[0,0] == np.dot(W_1[0, :], x_batch[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 0 7]]\n",
      "[[0.09  0.245 0.665]\n",
      " [0.018 0.001 0.981]]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def relu(x: np.array) -> np.array:\n",
    "    \"\"\"Return the ReLU of the input.\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Return the derivative of the ReLU of the input.\n",
    "    \"\"\"\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Return the softmax of the input.\n",
    "\n",
    "    The softmax function is a generalization of the logistic function that \"squashes\" a\n",
    "    K-dimensional\n",
    "    vector z of arbitrary real values to a K-dimensional vector sigma(z) of real values in the\n",
    "    range (0, 1) that add up to 1.\n",
    "\n",
    "    In other words, the softmax function transforms a vector of real values into a probability\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / exp_x.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "def softmax_derivative(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Return the derivative of the softmax of the input.\n",
    "    https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1\n",
    "    \"\"\"\n",
    "    return softmax(x) * (1 - softmax(x))\n",
    "\n",
    "\n",
    "example = np.array([\n",
    "    [1, 2, 3],\n",
    "    [3, 0, 7],\n",
    "])\n",
    "print(example)\n",
    "print(softmax(example).round(3))\n",
    "print(softmax(example).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # activations for first layer\n",
    "# Z_1 = (W_1 @ x_batch.T) + b_1  # pre-activations for layer 1\n",
    "# A_1 = relu(Z_1)  # activations for layer 1\n",
    "# print(f\"({W_1.shape} @ {x_batch.T.shape}) + {b_1.shape} = ({A_1.shape})\")\n",
    "# Z_2 = (W_2 @ A_1) + b_2  # pre-activations for layer 2\n",
    "# A_2 = softmax(Z_2)  # activations for layer 2 are probabilities\n",
    "# # our output size is 27 which happens to be the same as the input size (but in general doesn't\n",
    "# # have to be the same)\n",
    "# # so the result is 27 outputs for each of the 32 examples\n",
    "# print(f\"({W_2.shape} @ {A_1.shape}) + {b_2.shape} = ({A_2.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's swap the shape of the weights so that we don't have to transpose and end up with a 32x27 rather than a 27x32 matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 50)\n",
      "(1, 50)\n",
      "(50, 27)\n",
      "(1, 27)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "input_size = len(characters)\n",
    "hidden_size = 50\n",
    "output_size = len(characters)\n",
    "\n",
    "# weights between input and hidden layer\n",
    "# W_1 = rng.normal(size=(hidden_size, input_size)) * 0.01\n",
    "W_1 = rng.normal(size=(input_size, hidden_size)) * 0.01\n",
    "# biases of the hidden layer\n",
    "# b_1 = np.zeros((hidden_size, 1))\n",
    "b_1 = np.zeros((1, hidden_size))\n",
    "# W_2 = rng.normal(size=(output_size, hidden_size)) * 0.01\n",
    "W_2 = rng.normal(size=(hidden_size, output_size)) * 0.01\n",
    "# b_2 = np.zeros((output_size, 1))\n",
    "b_2 = np.zeros((1, output_size))\n",
    "\n",
    "print(W_1.shape)\n",
    "print(b_1.shape)\n",
    "print(W_2.shape)\n",
    "print(b_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((32, 27) @ (27, 50)) + (1, 50) = ((32, 50))\n",
      "(32, 50) @ (50, 27) + (1, 27) = ((32, 27))\n",
      "(32, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activations for first layer\n",
    "z_1 = (x_batch @ W_1) + b_1  # pre-activations for layer 1\n",
    "A_1 = relu(z_1)  # activations for layer 1\n",
    "print(f\"({x_batch.shape} @ {W_1.shape}) + {b_1.shape} = ({A_1.shape})\")\n",
    "Z_2 = (A_1 @ W_2) + b_2  # pre-activations for layer 2\n",
    "print(f\"{A_1.shape} @ {W_2.shape} + {b_2.shape} = ({Z_2.shape})\")\n",
    "# A_Z is refered to as \"logits\"\n",
    "A_2 = softmax(Z_2)  # activations for layer 2 are probabilities\n",
    "# # our output size is 27 which happens to be the same as the input size (but in general doesn't\n",
    "# # have to be the same)\n",
    "# # so the result is 27 outputs for each of the 32 examples\n",
    "print(A_2.shape)\n",
    "A_2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 27), (32, 27))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss via cross-entropy\n",
    "# we want to minimize the cross-entropy loss\n",
    "# we want to maximize the log likelihood\n",
    "# we want to minimize the negative log likelihood\n",
    "# the negative log likelihood is the cross-entropy loss\n",
    "predicted_probabilities = A_2\n",
    "# each row is an example (batch size of 32), each column is a class probability (27 characters)\n",
    "# this means that each row should sum to 1\n",
    "assert (predicted_probabilities.sum(axis=1).round(7) == 1).all()\n",
    "# what is the probability associated with the actual/correct character for each example?\n",
    "predicted_probabilities.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03704604, 0.03703422, 0.03704669, 0.03707962, 0.03704387,\n",
       "       0.03705516, 0.03703479, 0.03701309, 0.03705521, 0.03705294,\n",
       "       0.03702826, 0.03704387, 0.03703125, 0.03704525, 0.03707254,\n",
       "       0.03704387, 0.03703706, 0.0370181 , 0.03704728, 0.03704484,\n",
       "       0.03699079, 0.03703334, 0.03702542, 0.03704438, 0.03704387,\n",
       "       0.03705072, 0.03705704, 0.03705362, 0.03702426, 0.03704956,\n",
       "       0.03702826, 0.03704387])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_indices = np.arange(y_batch.shape[0])\n",
    "column_indices = np.argmax(y_batch, axis=1)\n",
    "pred_prob_of_actual = predicted_probabilities[row_indices, column_indices]\n",
    "assert len(pred_prob_of_actual) == y_batch.shape[0]\n",
    "pred_prob_of_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (negative log likelihood) = 3.2957239985861353\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = np.log(pred_prob_of_actual).mean()\n",
    "negative_log_likelihood = -log_likelihood\n",
    "# I believe negative log likelihood is the same as cross-entropy loss\n",
    "print(f\"loss (negative log likelihood) = {negative_log_likelihood}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat GPT Explanation of Backpropegation \n",
    "\n",
    "### Goal of Finding the Derivative of the Loss Function\n",
    "\n",
    "The primary goal of finding the derivative (or gradient) of the loss function with respect to the network's parameters (weights and biases) is to understand how changes in those parameters affect the loss. This understanding allows us to adjust the parameters in a way that minimizes the loss, thereby improving the model's predictions. The process of using these derivatives to update the network's parameters is known as gradient descent.\n",
    "\n",
    "### Backpropagation Explained\n",
    "\n",
    "Backpropagation is the algorithm used for efficiently computing these gradients. It works by:\n",
    "\n",
    "1. **Performing a forward pass** through the network to calculate the outputs (and intermediate activations) for a given input.\n",
    "2. **Computing the loss** by comparing the network's output to the true labels.\n",
    "3. **Propagating the loss backward** through the network, layer by layer, to find the gradient of the loss with respect to each parameter.\n",
    "\n",
    "### Your Layers and Forward Pass\n",
    "\n",
    "Your setup defines a simple 2-layer neural network (1 hidden layer and 1 output layer). The weight initialization and biases look appropriate, using a small random value for weights to break symmetry and zeros for biases. \n",
    "\n",
    "The forward pass correctly calculates the pre-activation values (`Z_1` and `Z_2`), applies the ReLU activation function to the hidden layer, and uses the softmax function for the output layer to get a probability distribution.\n",
    "\n",
    "### Computing Negative Log Likelihood\n",
    "\n",
    "The negative log-likelihood loss function you've implemented calculates how likely the true labels are given the predictions. By minimizing this loss, you're effectively making the true labels more probable under the model's predictions. The calculation of `negative_log_likelihood` you've shown is correct for a batch of examples, where you first ensure the predicted probabilities sum to 1, then select the log probability of the true class for each example, and finally take the mean negative log likelihood across the batch.\n",
    "\n",
    "### Backpropagation from the Loss Function\n",
    "\n",
    "To perform backpropagation starting from the negative log likelihood:\n",
    "\n",
    "1. **Gradient of Negative Log Likelihood (NLL) with respect to \\(A_2\\)**:\n",
    "   The first step in backpropagation is to compute the derivative of the loss function with respect to the outputs of the network (\\(A_2\\)). For the negative log likelihood combined with softmax, this gradient simplifies to \\((A_2 - Y)\\), where \\(A_2\\) is the predicted probabilities and \\(Y\\) is the one-hot encoded true labels.\n",
    "\n",
    "   https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1\n",
    "\n",
    "2. **Backpropagate through Layer 2**:\n",
    "   - **Gradient w.r.t. \\(W_2\\)**: Use \\(\\frac{\\partial \\text{NLL}}{\\partial W_2} = A_1^T \\cdot (A_2 - Y)\\)\n",
    "   - **Gradient w.r.t. \\(b_2\\)**: Use \\(\\frac{\\partial \\text{NLL}}{\\partial b_2} = \\sum(A_2 - Y)\\)\n",
    "   - **Gradient w.r.t. \\(A_1\\)**: Needed for further backpropagation, \\(\\frac{\\partial \\text{NLL}}{\\partial A_1} = (A_2 - Y) \\cdot W_2^T\\)\n",
    "\n",
    "3. **Backpropagate through Layer 1**:\n",
    "   Since \\(A_1 = \\text{ReLU}(Z_1)\\), you need the gradient of ReLU to continue. The ReLU derivative is 1 for positive inputs and 0 for non-positive inputs.\n",
    "   - **Gradient w.r.t. \\(Z_1\\)**: \\(\\frac{\\partial \\text{NLL}}{\\partial Z_1} = \\frac{\\partial \\text{NLL}}{\\partial A_1} \\cdot \\text{ReLU}'(Z_1)\\)\n",
    "   - **Gradient w.r.t. \\(W_1\\)** and \\(b_1\\) follow similarly to \\(W_2\\) and \\(b_2\\).\n",
    "\n",
    "### Key Considerations\n",
    "\n",
    "- Ensure gradients are computed correctly for each layer, considering the dimensions of matrices during multiplication.\n",
    "- When implementing backpropagation, remember to average gradients over the batch size if your loss was computed as a mean over the batch.\n",
    "- The negative log likelihood and softmax make a good pair for multi-class classification due to the simplicity of their gradient computation, as discussed.\n",
    "\n",
    "If you have any specific questions about the implementation details or need further clarification on any step, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Explanation of Derivative of Softmax and Negative Log Likelihood\n",
    "\n",
    "### Softmax Function\n",
    "\n",
    "The softmax function is applied to logits (the raw outputs from the neural network's last linear layer) to convert them into probabilities. For a given vector of logits \\(Z\\) for a single sample, the softmax function for the \\(i\\)-th element is defined as:\n",
    "\n",
    "\\[ \\sigma(Z)_i = \\frac{e^{Z_i}}{\\sum_{j}1 e^{Z_j}} \\]\n",
    "\n",
    "This results in a probability distribution over classes, where each element \\( \\sigma(Z)_i \\) represents the model's predicted probability that the sample belongs to class \\(i\\).\n",
    "\n",
    "### Negative Log Likelihood (NLL)\n",
    "\n",
    "The NLL for multi-class classification, when using the softmax probabilities, is defined as:\n",
    "\n",
    "\\[ L = -\\sum_{i} Y_i \\log(\\sigma(Z)_i) \\]\n",
    "\n",
    "where \\(Y_i\\) is the true distribution (typically one-hot encoded), and \\(\\log(\\sigma(Z)_i)\\) is the logarithm of the predicted probability for class \\(i\\).\n",
    "\n",
    "### Derivation of the Gradient Simplification\n",
    "\n",
    "When you combine the softmax function with the NLL and compute the derivative of the loss \\(L\\) with respect to the logits \\(Z\\), you're interested in how changes in \\(Z\\) affect the loss. For a specific class \\(i\\), this derivative can be shown through calculus to simplify to the difference between the predicted probabilities and the actual labels:\n",
    "\n",
    "\\[ \\frac{\\partial L}{\\partial Z_i} = \\sigma(Z)_i - Y_i \\]\n",
    "\n",
    "Heres an intuitive breakdown of the derivation:\n",
    "\n",
    "1. **Softmax Gradient**: First, you find the derivative of the softmax function with respect to its inputs. This involves some calculus, especially because the softmax function of a particular class depends not only on its own logit but also on the sum of exponentials of all logits. The result shows how the probability of class \\(i\\) changes with a small change in any logit \\(Z_j\\).\n",
    "\n",
    "2. **Chain Rule Application**: Then, by applying the chain rule, you calculate the derivative of the NLL loss with respect to the logits. This involves taking into account how a change in each logit \\(Z_j\\) affects all the softmax probabilities, and in turn, how these changes in probabilities affect the NLL loss.\n",
    "\n",
    "3. **Simplification**: The detailed calculus shows that, for the true class (\\(Y_i = 1\\)), the derivative of the NLL loss with respect to its logit is the predicted probability minus one. For all other classes (\\(Y_i = 0\\)), it's just the predicted probability. When you sum up these effects for all classes, the result for each logit \\(Z_i\\) ends up being the predicted probability of class \\(i\\) minus the true label \\(Y_i\\).\n",
    "\n",
    "### Why It's Elegant\n",
    "\n",
    "This result is particularly elegant and useful for a few reasons:\n",
    "\n",
    "- **Simplicity**: The gradient \\((A_2 - Y)\\) is straightforward to compute and understand. It directly reflects the difference between what the model predicts and the actual labels.\n",
    "- **Efficiency**: This simplification allows for efficient computation of gradients without needing to explicitly calculate the derivative of the softmax and NLL separately.\n",
    "- **Intuitiveness**: The gradient essentially tells you how to adjust the logits to reduce the loss. If a class's predicted probability is too high compared to the true label, the corresponding logit needs to decrease, and vice versa.\n",
    "\n",
    "This simplification is a cornerstone of training neural networks for classification tasks, as it directly connects the model's predictions with the direction and magnitude of adjustments needed to reduce the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of loss w.r.t. pre-activations of layer 2\n",
    "# specifically, we want to know how the loss changes with respect to the pre-activations of layer 2\n",
    "# i.e. the logits\n",
    "# because of the chain rule, we can break this down into two steps\n",
    "# 1. derivative of loss w.r.t. activations of layer 2 (i.e. the outputs of the softmax function)\n",
    "# 2. derivative of activations of layer 2 w.r.t. pre-activations of layer 2\n",
    "# after some calculus, we find that the derivative of the cross-entropy loss w.r.t. the\n",
    "# pre-activations of layer 2 is simply the difference between the predicted probabilities and the\n",
    "# actual probabilities\n",
    "dZ_2 = A_2 - y_batch\n",
    "\n",
    "# Step 2: Gradients of loss w.r.t. W_2 and b_2\n",
    "dW_2 = A_1.T @ dZ_2 / y_batch.shape[0]\n",
    "db_2 = np.sum(dZ_2, axis=0, keepdims=True) / y_batch.shape[0]\n",
    "\n",
    "# Step 3: Backpropagation through ReLU activation\n",
    "dA_1 = dZ_2 @ W_2.T\n",
    "dZ_1 = dA_1 * (z_1 > 0)  # Derivative of ReLU is 1 if Z_1 > 0 else 0\n",
    "\n",
    "# Step 4: Gradients of loss w.r.t. W_1 and b_1\n",
    "dW_1 = x_batch.T @ dZ_1 / y_batch.shape[0]\n",
    "db_1 = np.sum(dZ_1, axis=0, keepdims=True) / y_batch.shape[0]\n",
    "\n",
    "# Step 5: Update the weights and biases\n",
    "learning_rate = 0.01\n",
    "W_1 -= learning_rate * dW_1\n",
    "b_1 -= learning_rate * db_1\n",
    "W_2 -= learning_rate * dW_2\n",
    "b_2 -= learning_rate * db_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(z: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the ReLU of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, z)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def relu(z: np.array) -> np.array:\n",
    "    \"\"\"Return the ReLU of the input.\"\"\"\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z: np.array) -> np.array:\n",
    "    \"\"\"Return the derivative of the ReLU of the input.\"\"\"\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def softmax(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Return the softmax of the input.\n",
    "\n",
    "    The softmax function is a generalization of the logistic function that \"squashes\" a\n",
    "    K-dimensional\n",
    "    vector z of arbitrary real values to a K-dimensional vector sigma(z) of real values in the\n",
    "    range (0, 1) that add up to 1.\n",
    "\n",
    "    In other words, the softmax function transforms a vector of real values into a probability\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / exp_x.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "def forward_pass(x: np.array, params: dict) -> tuple[np.array, dict]:\n",
    "    \"\"\"\n",
    "    Return the output of a forward pass through the network, as well as the cache.\n",
    "\n",
    "    The cache contains the pre-activations and activations for each layer.\n",
    "    \"\"\"\n",
    "    W_1 = params[\"W_1\"]\n",
    "    b_1 = params[\"b_1\"]\n",
    "    W_2 = params[\"W_2\"]\n",
    "    b_2 = params[\"b_2\"]\n",
    "    Z_1 = (x @ W_1) + b_1  # pre-activations for layer 1\n",
    "    A_1 = relu(Z_1)  # activations for layer 1\n",
    "    Z_2 = (A_1 @ W_2) + b_2  # pre-activations for layer 2\n",
    "    # A_Z is refered to as \"logits\"\n",
    "    A_2 = softmax(Z_2)  # activations for layer 2 are probabilities\n",
    "    cache = {\n",
    "        \"Z_1\": Z_1,\n",
    "        \"A_1\": A_1,\n",
    "        \"Z_2\": Z_2,\n",
    "        \"A_2\": A_2,\n",
    "    }\n",
    "    return A_2, cache\n",
    "\n",
    "def backward_pass(x: np.array, y: np.array, params: dict, cache: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Return the gradients of the loss w.r.t. the parameters of the network.\n",
    "\n",
    "    The gradients are computed using backpropagation.\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    W_2 = params['W_2']\n",
    "    A_1 = cache['A_1']\n",
    "    A_2 = cache['A_2']\n",
    "    Z_1 = cache['Z_1']\n",
    "    # step 1: Gradients of loss w.r.t. pre-activations of layer 2\n",
    "    dZ_2 = A_2 - y_batch\n",
    "    # Step 2: Gradients of loss w.r.t. W_2 and b_2\n",
    "    dW_2 = (A_1.T @ dZ_2) / m\n",
    "    db_2 = np.sum(dZ_2, axis=0, keepdims=True) / m\n",
    "    # Step 3: Backpropagation through ReLU activation\n",
    "    dA_1 = dZ_2 @ W_2.T\n",
    "    dZ_1 = dA_1 * relu_derivative(Z_1)\n",
    "    # Step 4: Gradients of loss w.r.t. W_1 and b_1\n",
    "    dW_1 = x.T @ dZ_1 / m\n",
    "    db_1 = np.sum(dZ_1, axis=0, keepdims=True) / m\n",
    "    return {\n",
    "        \"dW_1\": dW_1,\n",
    "        \"db_1\": db_1,\n",
    "        \"dW_2\": dW_2,\n",
    "        \"db_2\": db_2,\n",
    "    }\n",
    "\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "    params['W1'] -= learning_rate * grads['dW1']\n",
    "    params['b1'] -= learning_rate * grads['db1']\n",
    "    params['W2'] -= learning_rate * grads['dW2']\n",
    "    params['b2'] -= learning_rate * grads['db2']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 50)\n",
      "(1, 50)\n",
      "(50, 27)\n",
      "(1, 27)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "input_size = len(characters)\n",
    "hidden_size = 50\n",
    "output_size = len(characters)\n",
    "\n",
    "# weights between input and hidden layer\n",
    "W_1 = rng.normal(size=(input_size, hidden_size)) * 0.01\n",
    "# biases of the hidden layer\n",
    "b_1 = np.zeros((1, hidden_size))\n",
    "# weights between hidden layer and output\n",
    "W_2 = rng.normal(size=(hidden_size, output_size)) * 0.01\n",
    "# biases of the output layer\n",
    "b_2 = np.zeros((1, output_size))\n",
    "\n",
    "print(W_1.shape)\n",
    "print(b_1.shape)\n",
    "print(W_2.shape)\n",
    "print(b_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAGfCAYAAABsni/uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwx0lEQVR4nO3deXzU5bU/8E9mkpnsMwmBhEACYUdAlMgScWNRXIoitLVqW7S2KgZ+Anajt+pPW4vVe9WrRrSWQq1FKveKFrRwNUpQWYQAshoWgQSSCQTITLaZTGa+9w8kbW7mnBBAiY+f9+uVP5gzzzPf+U7OfMmcOc8TZVmWBSIyiu18HwARnXtMbCIDMbGJDMTEJjIQE5vIQExsIgMxsYkMxMQmMhATm8hATGwiA0V/WRMXFBTgySefhMfjwdChQ/Hcc89hxIgRbY4Lh8MoLy9HUlISoqKivqzDI/pasiwLNTU1yMzMhM2mXJetL8HixYsth8Nh/elPf7J27Nhh/eQnP7HcbrdVWVnZ5tiysjILAH/4wx/lp6ysTM2jKMs6900gI0eOxPDhw/H8888DOHkVzsrKwowZM/DLX/5SHev1euF2u9FjzoOwxca2vkN2nTo+ZUW8GDs6JqiOzR+2SozN23qFGLMfiHCc/8IWlP/nEbarQ2E55ZcnSnk67ouq1HljX3SLsbp7fOrYmi2pYiyYHVDHpnzsFGO9frBHjPmbYtR5qxrk1z3qz2nq2IbbvGLM65XnzXxL/w9v+RXKFdWl/y5GOyPHww0BHLzvP1BdXQ2XyyWPV2c/A42NjSguLsacOXOab7PZbBg/fjzWrl3b6v6BQACBwD9/GWpqak6OiY2NnNjxIfXx7Q45yWxxehbFJsqnwxavzBvpOP/1mGxyYke18QqEtcRWno49QU4gAIiOkY/ZHq8np115vqE4/c8nu0M+rpgEhzxvG4kdbZPnjVKeKwDY4/1izNYoj42O0V88W5yS2G38Ltpi9Xhbf6ae8w/PqqqqEAqFkJ6e3uL29PR0eDyeVvefO3cuXC5X809WVta5PiSib5zz/qn4nDlz4PV6m3/KysrO9yERfe2d8/+Kp6WlwW63o7KyssXtlZWVyMjIaHV/p9MJp1P/byMRtc85T2yHw4Hc3FwUFhZi0qRJAE5+eFZYWIjp06ef9jxBVwi2uAh/T9fJf4cBwJAZ28RYpT9JHfvOiO5izP4r5e9K/U84ZH4sf1By4Eb9b6Whgw6KsUOv9hJjld3lD1YAwN1H/ps1+KH+YdPlkz8VYx//fag69sSYBjF29MEcMXbts6vUeefvvFSMhUbq/zGNqpcvLBlvy79viTNL1Xlj1vQQY2G//ntsrxOOKXB6Kful1LFnz56NqVOn4pJLLsGIESPwzDPPoK6uDnfeeeeX8XBE9H98KYl9yy234OjRo3jooYfg8Xhw0UUXYcWKFa0+UCOiL8eX9s2z6dOnt+u/3kR07pz3T8WJ6NxjYhMZiIlNZCAmNpGBvrQPz85W3KFo2J0RDi9X/sI+ALy3baA8p1v+TjAA+H/XU4zZO8v11+g9cqMAAPz0+b+Iscd/NlUdaxscFmP97vhMjO14XT4PAPDbmX8SY3P3Xq+O3XlCrm74M9r4Lv8huehfOkEeN6/4SnXey/rtFWMfHh+gjnV9nCjG/LcfE2PHlcYTALD3rxFjzmj9PPl3uSPeHo46vZ4tXrGJDMTEJjIQE5vIQExsIgMxsYkMxMQmMlCHLXc5agB7hBV6wqv1dsTsz5vEWOmNcepYm1KBiN4tlzZ6PLZRnffRfXJXm3u6vrDE7rf7irH6gfISRhmVcpkMAP6rargY82zvoo4NpcjneMH1L6tjXz8ur1T73rsXi7G4z/Te2PWHBomx6By5VAkAtT3l61u0sr5b7oSt6rwf7Boixp6bpJ+nH5ffFfH2sEMvk53CKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBmJiExnoS9m762z4fD64XC7MWTsBsYmtl8j906bR6viuGSfkuQtbr2v+r2yNcqx2uFwL7Zqmt5KW7+ksxjp/or+32pqULX6UUrWzWq41A8CBm+TH7de/XB27Z7u8THP/+dXq2L3fTxFjlrIS8yM3vq7O+8Kvvy3Gjg3Rz/G3b/xIjL22/RIxZm+j9TJ4Qqm9x+pjk1PqI94eqg9g161PwOv1Ijk5WRzPKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBuqwbZtvvnol7M7W5YJO46rUceE/yy2HtdfIbY4AgIBdDMXvkFs+yzP0bYDjPPL7Z1OcXm2szZZrQEkH5HEV1+rzpn0oP9fDGXprbKct8jGVfktucwQAh1yNxKAbSsTYr9dMUueNvkQ+x1aW3ra58ScXycHb5df2pxP+rs47d9W3xFhUvZ56DbGRd+MMN+jtuKfwik1kICY2kYGY2EQGYmITGYiJTWQgJjaRgTpsucs5pgr2+NalBvfvEtRxjW6layaov48l7pNPx8Cb5FLMp0X91Hkz18jlFl+2vvpm76flx93zs/5iLPpo5HLJKTU95JJVt2R5MzkAiJt6XIyVfNJTHdv7dXnurRdnirGYWL1bLdhZeT6pPnXssSHyJoO/mrBUjD3//GR13qSr5dpe6h/kjQABwNsr8u95qFEuU/4rXrGJDMTEJjIQE5vIQExsIgMxsYkMxMQmMhATm8hAHbaOfXHaITgSW9di35so78gIAEmDjslBj96O2JAht8RFK0uChtsoLYac8h38acrSnAD2Pp8lzxuU21C7LW29wuu/qu4jH5PnfXkVUkBvNU3bqbeLll0tr6wZs0EeZxut9HsCSIiXz4Vnm1ynBoDonnLst0U3irFk/asCcCxzizFvjv66NyZFvj3URufxKbxiExmIiU1kICY2kYGY2EQGYmITGYiJTWSgDlvu2jR/KOyO1i2NwRH6ZmaNTfJTynpbLzEcGieXajZ8OECMNaUru/kBOHCDXHrq+pH+fGKPxYuxo8PlEpx9WqU6b/efy/OWzJRXZAWAC3rKm/Z9FttTHWvrXifGnJvllty6fXqpstsq+Vx03auvbHviKXmsf5lcKvPLey0CABIqlNJfbRur0wpttWH/6e2hySs2kYGY2EQGYmITGYiJTWQgJjaRgZjYRAZiYhMZqMPWsf0pUbA7W9fyouL0ZWjr6+TdEWtvbGOnwpBc574ub5MY+/gPl6jTVg+Ua4+J9x5WxybEyH169oLeYqzC11WdN7fgMzFmO9hDHbujRG7rjNbL8rDtkevntf3l7wPEHNXbUA+NU3bbvFbfATR+ldzCGrisXoztuWqhOu+YO38sxg58T69HJ22P/HscCujfxTiFV2wiAzGxiQzExCYyEBObyEBMbCIDMbGJDNTuctfq1avx5JNPori4GBUVFVi6dCkmTZrUHLcsCw8//DBefvllVFdXY/To0Zg3bx769u3brsdpvLgWtvgIpa0qvaUwobu8s2J3l1cdu2t3NzFW4pXb99I/1NsCL79nvxj7+/YL1bE53eS5m2Ll0kfsUb0ssnab/HpEBdp4v0+US47Zl+jlu/CTXcRY4yx5F8+KOr1H0t4gH3OXj/XSUuXNckmr38Py79PA3/1AnbdTklxGi5K7VwEA9ZmRS7Nhfxsl2y+0+4pdV1eHoUOHoqCgIGL8iSeewLPPPosXX3wR69evR0JCAiZMmAC/39/ehyKiM9TuK/Z1112H6667LmLMsiw888wz+PWvf42bbroJAPDKK68gPT0db775Jr73ve+d3dES0Wk5p39j79+/Hx6PB+PHj2++zeVyYeTIkVi7dm3EMYFAAD6fr8UPEZ2dc5rYHo8HAJCe3vLv0fT09ObY/zV37ly4XK7mn6wseecLIjo95/1T8Tlz5sDr9Tb/lJWVne9DIvraO6eJnZGRAQCorGy5kF5lZWVz7P9yOp1ITk5u8UNEZ+ecdnfl5OQgIyMDhYWFuOiiiwAAPp8P69evx7Rp09o1V68uxxCd0LrDZU+p3nlkrUkRYweccgwALr56jxjbfjhTjNlulTuWAGDPu2lirNt6vXyxf5I8tocnKMb8N7dRT6kQdn0DsGhi5IrHKdPnThdjB6vl8wQAP3ryAzG25ngvMeY7pO98WNtHPhcVl+vXL6tBToOymyNfkACgsUx/7WxBOW61sZGjJax8a9Wf3q587U7s2tpa7N27t/nf+/fvx5YtW5Camors7GzMnDkTv/3tb9G3b1/k5OTgwQcfRGZmZotaNxF9udqd2Bs3bsSYMWOa/z179mwAwNSpU7Fw4UL8/Oc/R11dHe6++25UV1fjsssuw4oVKxAb23qNcCL6crQ7sa+66ipYlvxNnqioKDz66KN49NFHz+rAiOjMnfdPxYno3GNiExmIiU1kICY2kYE67Cql+zZmwxbhk/Sua/VlMMPT5DbHco9ex96zTGktTZU/MEz7VK9n1neW3z+PDdILmoN7HhRjn18s131DQb3eGXdYfulvLbxXHWvvL5+LlP5y6yUAvPr6ODGWtl1uB02M089xyCGvYppUqrdtHh0v18CblC7hVya9oM776/+5Rw62cUlN+SByFSnUCJTqQ09neiL6OmJiExmIiU1kICY2kYGY2EQGYmITGajDlrvsDVGwh1uvtFkWebm1ZgNny0/p8Cz9feyuO94RYy+9fr0873V6Ca5HdqUY832qb563b6Vc0speLpeWDuTqm9g1psjlo5Ri/dfixFD5+davkdtMAaiXkiO3NcjH9GaCOm36lfLqqIH5+jmO3yE3KN3zw7fF2KP7b1TnPXCjvFKse6t+juuFQ+amfETfYExsIgMxsYkMxMQmMhATm8hATGwiAzGxiQwUZWkLmJ0HPp/v5I4g//Eb2OIi1Bfb2GwwKqjU+dp4G7MpNcIuxfJpOtFfnzg574gYi/qLXvetulg+pvgKOebrK7dAAoCzSm4XvXzCVnXsB/vk9ta0d/RFK32TasVY9Fp5TflQ65WoW6jvE3m5XgCIPeBQxyaNPCrG/O/Lu3yG9GkRpWSW1cbvYua4yBtnNNUFsHriC/B6veoa/LxiExmIiU1kICY2kYGY2EQGYmITGYiJTWSgDtu26ehcD3t869rWlL5b1HFXJH4mxn757z9Wx1YPkWtpjQnye2B0Gxtb1nzYRYzFJunVxuR9cszbVz7ezp/oq5+GphwTYxv/MlQdu/WXz4ix3JKZ6thApdx+2aVSfj7jf/qxOu+GY/IurLstecdMAHD/tZMYq7lKXsG00yd6+gz98TYxtqmyuzp2b0nkvs1wg18ddwqv2EQGYmITGYiJTWQgJjaRgZjYRAZiYhMZqMN2d43r9f8QbW/d0lNxjb7iZOM4rxjrnSaXeACgoUle2TPwnPy4ZTfqLWdZ3eTHjXpO7h4CgLKr5fdeK0Hu4Io5oq9SmvWe3A11aFwbbUuKtjqeHNVyR5qlHHKju422vjR5E0J7qd5xZlM6AgOd5XPc529yKQwA9t8tx8LH2moNE8Y1+FH2swfZ3UX0TcTEJjIQE5vIQExsIgMxsYkMxMQmMhATm8hAHbZt0/vvUYhOaF3MS3tM3pERALBVLoZuu0NvlYuqk0+Hda1cR409qNckq5LlVkVXvl5btx1XapVlcn2211J5NVAAqPg3uT7bP0XeuRIA9hyRa+9xHyapY4NXyt8zSHDKdeGR6QfVeT/6S64Yq8vUv6rhGHpCjDUeks//ib56fTwckmvr0V303+OmY3GRA6d5KeYVm8hATGwiAzGxiQzExCYyEBObyEBMbCIDddhyl+dQasRN+WJu0A/5yjHyhnJHX9VX3wwqlZqGDLlkkji8Sp3XuTBFjDXFJqpje+2TyyJ7b5NLcFVD9XkDyr57ey/QVzi1F8snyjtEb2WMKZHLR3X9asTYit0XqPNG2r+xWRuXr9R4+RzXJgtlJwCOWr3MGRsvt8bGr9TLghf8aEfE24N1jYi8XV9LvGITGYiJTWQgJjaRgZjYRAZiYhMZiIlNZCAmNpGBOmwdOyu7CtEJrZcfPmhPU8e9t3mQGIvu3kb7Xh+fGIvZKddfqypc6rxpd8htgXVr9edTkyW3fHbaJD+fsL76MLoVyTXWI8quowBw622FYmxPvbyzKAB8/thAMXZ8oPy4l/feq867bvcQMdaUGFLHOh5xizHrTvnaF0iWly0GgAap9RJApyr9HK87kBPx9nA9d9sk+sZiYhMZiIlNZCAmNpGBmNhEBmJiExmoXeWuuXPn4o033sBnn32GuLg4XHrppfj973+P/v37N9/H7/fjgQcewOLFixEIBDBhwgS88MILSE9PPycHnLRDb5VzeOUSUNoWuZwFAJ9/Wy5pxTTIpY0u7+jvj+VT5JKVo41XIK5Cfj51mfIxdR1zSJ338HG5RNe0Tz4PAPBKcIQYS1qht4seu0Yu81iV8th1W+RyFgA09pFbL5M2y2UnANifL5f+YqLkNtQur2xX5+16m9yuG7ynQh0bM+DSiLeHAnpL7SntumIXFRUhPz8f69atw7vvvotgMIhrrrkGdXV1zfeZNWsWli1bhiVLlqCoqAjl5eWYPHlyex6GiM5Su67YK1asaPHvhQsXokuXLiguLsYVV1wBr9eL+fPnY9GiRRg7diwAYMGCBRg4cCDWrVuHUaNGnbsjJyLRWf2N7fWeXPw9NTUVAFBcXIxgMIjx48c332fAgAHIzs7G2rVrI84RCATg8/la/BDR2TnjxA6Hw5g5cyZGjx6NwYMHAwA8Hg8cDgfcbneL+6anp8Pj8UScZ+7cuXC5XM0/WVlZZ3pIRPSFM07s/Px8bN++HYsXLz6rA5gzZw68Xm/zT1nZ6azoRESaM2oCmT59OpYvX47Vq1eje/d/7oeVkZGBxsZGVFdXt7hqV1ZWIiMjI+JcTqcTTmfrZg8iOnPtSmzLsjBjxgwsXboUq1atQk5Oyw6U3NxcxMTEoLCwEFOmTAEAlJSUoLS0FHl5eefkgAOd9A6tpDJl5c5hehknM1cuQcQ8JpcubA8dVefFVnkzwMRS/fnUd5VLWrHH5LE+v75hXEyM3PGUUah3Q3lGyStsNuqLb2LYRfvE2OF5fcTYyAc+Uedd9uElYsxZrZ/j8KfxYswuV8Jw/DsXq/Me2Smfx85Te6pjs1ZE3rywKRTAHnXkSe1K7Pz8fCxatAhvvfUWkpKSmv9udrlciIuLg8vlwl133YXZs2cjNTUVycnJmDFjBvLy8viJONFXqF2JPW/ePADAVVdd1eL2BQsW4I477gAAPP3007DZbJgyZUqLL6gQ0Ven3f8Vb0tsbCwKCgpQUFBwxgdFRGeH3xUnMhATm8hATGwiAzGxiQzUYVcprdyQAXts61pst9VKYRFA1VD5yy42fSiql2eKsftefFOMPV44UZ3XUlbJTCzXP5BsSJfbVE8MaxJjKcs7qfMm3CjX3uvT9VVXwzHyMTcl6Ct3Fu/oJR9Ttnydeed/hqvz2pSH9afqx+S/UG75DNXLKVJbo7dQxh6RxwYnH1fH7hsY+XsTYb8f+FQdCoBXbCIjMbGJDMTEJjIQE5vIQExsIgMxsYkM1GHLXVY0EI5wdPsn6yWGW/M+EmMfPBl55cdT6r8buVUOAF6/71oxZt2qb7A28eItYuydBHkTQQAI+eT33riD8s571YP01svorZ3FWGwb5SFALnfV95BX9QSApN3yMUcpp7HTVr0sWHmtXMsM9NDPRahWLilmZh0TYxX75HMIAIEceQM9/zF9NVebI/LzDYfb7tcAeMUmMhITm8hATGwiAzGxiQzExCYyEBObyEBMbCIDddg6tr0hCvZw63rq0999RR3307/8SJ6zjU1GGmrkJXt9t8n1866Fem29pLe806jl0ZcJ7rRTrilnfH+/GNt7JE2d17VcrqNO/On76thFu+WlfpsO6/XZsbfJywi/tWGYGKvtoV+D4nfK5zE4rFYda4+X218rdsu16sQD+ute01euOdv8+vPpXBz59lAjUKqO/GL+07gPEX3NMLGJDMTEJjIQE5vIQExsIgMxsYkM1GHLXe49IURH2BFy1sbvquP6/vGAGNv5UDd1bOyeODE25JoSMbatrL86b/UJtxiLqdVbJI/lyi2HgRPyDqBRO/RtL2Nu84ixN+aNUcc2XCK3Zqb3rVLH/s/+AWJs9uUrxdjLf7pBnTehXO75DPgS1LH+cTVirDFNLlnVRMvtngDQqVguhwW/Va2ODW9xR749Qgk4El6xiQzExCYyEBObyEBMbCIDMbGJDMTEJjJQhy13Jd11GNEJrTfYW9X/7+q4/o/dLcYccQH9QQ/LK2hW/f+eYsym7xeHuJVy6cnp1VedHPOrtWLsrxtHirGoXvIKmQBwtFjuOAvnqEOR2U3eUM7zWRd1rK2LfFzPLr9eHpein6fEQ3Ks0zZ50z0AONhDfn3CiXIZrct6/bpYlSsfs3UoWR3bdbsv4u1NoTZ+h7/AKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBmJiExmow9axK5dlw+5svfJk/+E/0QdGybXD5JV6+17VCHm1yqafybXb6AZ9pdETn7vEmMOrv7cu/dvlYsw+WK7Phmr1l9bWT165s7FKbl8FgIZGud4fdug7jybGy3VYx6B6+ZgK9VVXY4/Ju232f3qXOnbvp0PEWI//ltskjw3WVylN7Fktxhp2udWxpddH/p0JBfzAZnUoAF6xiYzExCYyEBObyEBMbCIDMbGJDMTEJjJQhy13Df7uTsQktF4FcsfCQeq4YIJcnqgaJa+uCQBRTnlF0PJjcskqza1v+uZLkOcNZujtlbZSufQUPqGskmnT2xz9J+QSXXJXedVOAKitk8dGtbWKZpG8suqxPvJ5Qk+9jOYbIF+jZrq3qWPfP5Arxspuk0uK2RlH1HkP7JFbY/98yzx17E/+Oi3i7eGw/rqewis2kYGY2EQGYmITGYiJTWQgJjaRgZjYRAZiYhMZqMPWsdfs7g1bXOt6aXK8XicNpCp1vjZKrCmpcj36+FF5udjMRK8679E6ueXQflR/CT6c+u9ibNQHM8RY4ja9lVQ7F7ZP5VozAHT6VqUYO743Xh3r6ye3xtr88nUmvmfk5Xibx65yi7FHiqeqY7XdQx0OubZ+4JDeSpq8R35tp6Xfro51eCO/QKEAd9sk+sZiYhMZiIlNZCAmNpGBmNhEBmJiExmoXeWuefPmYd68eThw4AAAYNCgQXjooYdw3XXXAQD8fj8eeOABLF68GIFAABMmTMALL7yA9HS5fU0Su98Ju7P1bps2eTFKAMCQK/eIsR2erurYuobWj3fK0N5lYuzVXm+r817/eL4YO3aBvOInAIx54WdiLEle1BPRDXp7X01PORandyPC43GLsagUvb3Snqy0zrrkYw4G9RVBrTR57G9uWaSO/UXRd8VY95fk1+dEf6VtFoBrv/xcD+YkqmNtGZHPY9ivn9/m8ad1ry90794djz/+OIqLi7Fx40aMHTsWN910E3bs2AEAmDVrFpYtW4YlS5agqKgI5eXlmDx5cnsegojOgXZdsSdOnNji34899hjmzZuHdevWoXv37pg/fz4WLVqEsWPHAgAWLFiAgQMHYt26dRg1atS5O2oiUp3x39ihUAiLFy9GXV0d8vLyUFxcjGAwiPHjxzffZ8CAAcjOzsbatfLm7YFAAD6fr8UPEZ2ddif2tm3bkJiYCKfTiXvvvRdLly7FBRdcAI/HA4fDAbfb3eL+6enp8Hg84nxz586Fy+Vq/snKymr3kyCiltqd2P3798eWLVuwfv16TJs2DVOnTsXOnTvP+ADmzJkDr9fb/FNWJn9IRUSnp91NIA6HA3369AEA5ObmYsOGDfjP//xP3HLLLWhsbER1dXWLq3ZlZSUyMjLE+ZxOJ5wRPv0mojN31t1d4XAYgUAAubm5iImJQWFhIaZMmQIAKCkpQWlpKfLy8to9r2UDrAgVjunT31DH/X7LBDHmjNVXKY0udIux0pBcnhh8gdxlBQDWjXIpptfr8iZ1AFB6rVxSaegqlz7s9fp/xuIr5S6h2u7qUEQflY+pKVFZaRRAdIzc3dUtVe6SK/ukmzqvvUl+PnPW65UZp0teKbb8iiQxFnuxvFEjAASdcm12WIL+WdJFrkMRb/fXBjFXHXlSuxJ7zpw5uO6665CdnY2amhosWrQIq1atwsqVK+FyuXDXXXdh9uzZSE1NRXJyMmbMmIG8vDx+Ik70FWtXYh85cgQ//OEPUVFRAZfLhQsvvBArV67E1VdfDQB4+umnYbPZMGXKlBZfUCGir1a7Env+/PlqPDY2FgUFBSgoKDirgyKis8PvihMZiIlNZCAmNpGBmNhEBuqwq5Q6vIA9QnnxsXdvOuM5Q03yzpUAEKd00rn3yjXjE3a9RTJJWa1y/xR91cnEfXLcUSO/Lx8bIdeLAcDnVuZN0XcAfXKY/F2CWau/p45tCsrnovp1uVadIm96CQAYef8GMfbhwuHqWFtQfv2qB8qve+M+tzqvtV9+fbZ21VuZG0dHPk/Bujb6lr/AKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBuqw5S7YEPFtJ2ONXh6yph4VY0dPyC14AGAdlTeUszXJJZHEz/XTWNddLpkMuEBfWKJyaw8xdmKgfEzxqcoSpgB6/EpuF61/Ti+VPfa7H8jBK/RyTKhePlfu7x4WY2VH9Y0C994un6fQDepQVA+WW02jvfLqqFZ3vSwY1Vuu0dkC+uq0u9blRLw97Ncfs3n+07oXEX2tMLGJDMTEJjIQE5vIQExsIgMxsYkMxMQmMlCHrWN32hFAdHTrmnX5Zfoa5I1VyWIsZXWsOrbumhp53svlmmTtwVR13n7TPhFjx36gL818+y9WirE/vnatGMt8Q6+TOv5QJcY++7SnOrb39yMvjQsAVQf0dkRbnFwj33+osxiLT9brtzPffkuMPbJ3ohgDAPeLaWLs8Lflx+3bVd+WNNomf39h36rIdermua88EPH2proAIkda4hWbyEBMbCIDMbGJDMTEJjIQE5vIQExsIgN12HJX/XQf7AmtWwuXD1qojpv03M/lOeXdfAEAoT3yMqVev9zy6arW57WnyC2Hvt56G+rzxVeJMafcUYhJfyhU5/2P964XY8Mu3qeOLS7pKcZSusglQwA4cVQ+j3kD5Mddt7mfOu99/tvFWLhROVEAokcorZlhuTw3I1s/x7OW3CnGQkpLJwDE2iPvDBu06y21p/CKTWQgJjaRgZjYRAZiYhMZiIlNZCAmNpGBoizL0neU+4r5fD64XC6MWX4vohNad3Lt3t5dHT+g4JgY2/OwsusegD5PyCtsdn/poBh7b/Mgdd6sHHnlVN/yrurYpEPyCpqHbpBjtlq9kuk4Lr+nB9LleQFg803PiLExm+5Qx7ri5G4pn1/u3BvWRV7BFABWFV0oxnKW6iu27r9ZXp02sf8JeeBKvauvtqecWrFVepnz0m9vjnh7Y20jXhnzN3i9XiQny52MvGITGYiJTWQgJjaRgZjYRAZiYhMZiIlNZCAmNpGBOmwde8BrP4c9vnVds6lJb8ELh+X6YLA8QR8bJ9dv09bJdeFOW3zqvCX3KI/r1GvGg3LKxVivRHml0bZ8NP8SMVbXTR8bypFr0ctGF6hjn6q8WoyV1srtrQc/zlLn1erC1lilFg0g5m23GPP1lseFY/TU+dZVG8XYP/4xXB3be6En4u1NoQAKP3+WdWyibyImNpGBmNhEBmJiExmIiU1kICY2kYE67CqlDfUO2NC63BW3RW6xAwB/tlw+ipL3SAMAxByXT0fTJLlkUud1qfPGHZZLdFEX1alj96+UN2/z7ZRLQFU/0FsVs75dJsa82/TW2F4vyrHvxP1EHdvpT3Lpr3Sy/AK52mhzjKmVS0+1W+QyGgDU95XHOo8r5dOL9ddu5bIRYqzzqMjlrFN2de0U8fZwgx/IV4cC4BWbyEhMbCIDMbGJDMTEJjIQE5vIQExsIgMxsYkM1GHr2LHb4mF3xra63dZ6A84WslbINcnSm/UWyeiKGDHW9efyLocHvqO3kjqq5dgVPXarY7fOv0iMBRPlx+2W4lXn7RQr12DLD+nv9+WXxYmxUJO+G2TC59VirNer8k6cZVfrLZLXjN8kxgrfzlXHNiXKvxe9cuW22Tu7f6zO+5tPbxVj5SVd1LH3jo28k6e/NohH1ZEn8YpNZCAmNpGBmNhEBmJiExmIiU1kICY2kYHOqtz1+OOPY86cObj//vvxzDPPAAD8fj8eeOABLF68GIFAABMmTMALL7yA9PT0ds2dvD+E6JjWZYjoeyrVcb43lN0r2yiVWcrZqBgvlyecx/V5q3PlXTw3Vemrb3rGyiWtcJxcAoo+qrcqVq1WHvfqanWs0y6Xh/576Hx17LW3/kyM2ZrkFsm4gfpKo2sqeoqxKL0CB+dR+YXfnxK5fRIA5i6Ty1kAEFJeAitG7yFednhIxNub6gIA3lPHAmdxxd6wYQNeeuklXHhhy+1LZ82ahWXLlmHJkiUoKipCeXk5Jk+efKYPQ0Rn4IwSu7a2FrfffjtefvllpKT8823J6/Vi/vz5eOqppzB27Fjk5uZiwYIFWLNmDdatW3fODpqIdGeU2Pn5+bjhhhswfvz4FrcXFxcjGAy2uH3AgAHIzs7G2rVrI84VCATg8/la/BDR2Wn339iLFy/Gpk2bsGHDhlYxj8cDh8MBt9vd4vb09HR4PJGXgpk7dy4eeeSR9h4GESnadcUuKyvD/fffj7/+9a+IjW39Pe4zMWfOHHi93uafsjJ5LS4iOj3tSuzi4mIcOXIEw4YNQ3R0NKKjo1FUVIRnn30W0dHRSE9PR2NjI6qrq1uMq6ysREZGRsQ5nU4nkpOTW/wQ0dlp13/Fx40bh23btrW47c4778SAAQPwi1/8AllZWYiJiUFhYSGmTJkCACgpKUFpaSny8vLadWDVfeywO1uXejJ+L5cfACA1JNe0Yupbr3r6r6JCcvmo6iJ5XMpOdVokljjEmG9n5De8U2LkhicMGVUixrZ7lLIfAO8AuWTl3OJWxypVKYw9dr861tFP7ipzfpQoxnxl+ht+n9fkjQL33BFUxyZ1qRVj/l1uMXbLjyJ3YJ3y+h/HibFAV71breKzyOXVsF9+nv+qXYmdlJSEwYMHt7gtISEBnTp1ar79rrvuwuzZs5Gamork5GTMmDEDeXl5GDVqVHseiojOwjnvx3766adhs9kwZcqUFl9QIaKvzlkn9qpVq1r8OzY2FgUFBSgo0PdJJqIvD78rTmQgJjaRgZjYRAZiYhMZqMOuUtrYKQxbbOvWtoPXyyuJAkAoTm6HS806po4d2OmIGDuysb/8mDdXq/PiI7n2HnW53o4Y86Hc+3fML+9c+fjQN9R5Zx/4oRjr8Xd9hdPS6+XdRYf0OqyO/axcbt/1XijXm7Oyq9R5P893y8fUXf8245E6uX5+2fjNYuyPmy5T502bcFSMxXyapo6NqYn8ZYFQ4PSuxbxiExmIiU1kICY2kYGY2EQGYmITGYiJTWSgDlvumnLlOjgTW5e2/vqJ3iXmTq8RY8cPudWxm9cqJYgMuc1xaBd54zYA+PhieVGKzJfkUgsAHL5Sbu8b00Xe0O+BN6aq82YXyqWla1/VN5t7+bPRYmzHpp7q2OhaueezV55cKqv4oLs6b59xB8WYVmIDgGCt3Fb7j9JUMRbt0zdjjM+Uz3GgUul9BeD+PPLSqk3BJuxRR57EKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBmJiExmow9ax39w7BPb41vXf2BR9+dWa2jgxFpWgb7vYlCDXJZOy5a2HVq8bpM7rOC6/f1Zcpi9D+8ubloqxV2dNFGPWDxvUecMxcvvr8yuuVcfG1MjPp8878vcIAGBPvvy4h9d0E2M93tXnPTpKbmEdnfO5OtZhk38v3t15gRgLaeswA8hIkH9nLr1DP6bi49kRb2+qCwD/UIcC4BWbyEhMbCIDMbGJDMTEJjIQE5vIQExsIgN12HJX3MdJsDtal7uqlZUsAcCmlLR6vqKXJ0rvlEtpTw7+LzF2f/B76ryX5cmljfe2yOUUAPjdiklizLq1UYwlbYhX5/X2kGMXDtcbA2Pt8jn+rHKAOrZreqUY8xyLvMMkAOyeJrdWAoDNK/8q74nprI4t3yfHLxu2S4x9uKufOu+Ww3L5btca/Tw9dN+rEW+vrwlhlTryJF6xiQzExCYyEBObyEBMbCIDMbGJDMTEJjJQhy131Y5ogC2+dedTQpxc4gGA1D/LXT7HButPd3D3fWLsniJ51c/ef5E3AgSAPb+Syylxpfomg5d8a7sY+3itXCrzDdDLggP7ySuCfr6krzrW1iR3pNX0VIcCjfLz7VwsD4ut1q9BvntqxdiJogx1rCNOfj6H/00+FwnD9RJcfab8+5YyQS77AcAjL30/4u2hgB/Ap+pYgFdsIiMxsYkMxMQmMhATm8hATGwiAzGxiQzExCYyUIetY984YGvE3Tbfee1SddyJ/nLsyu8ohVIAb2++UIzFHZTrrwdu0FcaHZHgFWO9J1apYzf+TT4m9FDq5yG9RdXzuty3WdNPr8tbdvn59ht8SB0bbZPn3nOBvLNlOFr/VY1R6uNR+qmA1b9OjB1IlNtfk/fq87p2y9fNC0bqdeyijMgtrGG//rt2Cq/YRAZiYhMZiIlNZCAmNpGBmNhEBmJiExmow5a7wlYUwlbrOkXIqY9r6Cm3dX6/0xp17NqNw8RYym55BVP3b0rVeXcsGSjGanL00lKcvMcgwonyaqHuzXpLYU2OUjbpHFDHuj9uvXrsKYcPKcufAmhMlh+30zY5dvwC/RrUcFQuSzlj9RKR9bnc6mtFaB0+JZisTgtruFzmDEOvwcXURo6H/G3U7r7AKzaRgZjYRAZiYhMZiIlNZCAmNpGBmNhEBmJiExmow9axl5cMgS2+db3UlqDXJKOUlsJFx0epY71XNYix5IPyqdp8MEudd9DN8m6bu9bmqGNTrvCIMdv78rK6CZUhdd7qIfJ56vkXuzr28Bg5duHo3frjPpgtxmqy5C8pxFfor3swWb5GRfg6RAujrtohxvZ508RYZWe9kB06KtfHi+r0JZ6TqoU59a8YNOMVm8hATGwiAzGxiQzExCYyEBObyEAd7lNxyzr56We4Qfj4T26y+mKc3N3VWKtvVBeulydvapJPVbhe/wQ6WCcfU9ivP6GmOvlj0JMbtAnjgvoxhRvkT5mbmvSOs7Bfnlt7rifnlo851CgfU0jfu1Bd5C/cRkeUdsza+dd+XwAg3CCfx6gouTMPkD/9DjWefMxTeSLOb7V1j6/YoUOHkJWll4+IvunKysrQvXt3Md7hEjscDqO8vBxJSUmIioqCz+dDVlYWysrKkJzcRgPsNxjP0+n5up8ny7JQU1ODzMxM2GzyX9Id7r/iNpst4jtRcnLy1/KF+KrxPJ2er/N5crlcbd6HH54RGYiJTWSgDp/YTqcTDz/8MJzONhY7+4bjeTo935Tz1OE+PCOis9fhr9hE1H5MbCIDMbGJDMTEJjJQh0/sgoIC9OzZE7GxsRg5ciQ++eST831I59Xq1asxceJEZGZmIioqCm+++WaLuGVZeOihh9C1a1fExcVh/Pjx2LNnz/k52PNk7ty5GD58OJKSktClSxdMmjQJJSUlLe7j9/uRn5+PTp06ITExEVOmTEFlpb4Z/ddJh07sv/3tb5g9ezYefvhhbNq0CUOHDsWECRNw5MiR831o501dXR2GDh2KgoKCiPEnnngCzz77LF588UWsX78eCQkJmDBhAvxtNJuYpKioCPn5+Vi3bh3effddBINBXHPNNairq2u+z6xZs7Bs2TIsWbIERUVFKC8vx+TJk8/jUZ9jVgc2YsQIKz8/v/nfoVDIyszMtObOnXsej6rjAGAtXbq0+d/hcNjKyMiwnnzyyebbqqurLafTab322mvn4Qg7hiNHjlgArKKiIsuyTp6TmJgYa8mSJc332bVrlwXAWrt27fk6zHOqw16xGxsbUVxcjPHjxzffZrPZMH78eKxdu/Y8HlnHtX//fng8nhbnzOVyYeTIkd/oc+b1ntwcLzU1FQBQXFyMYDDY4jwNGDAA2dnZxpynDpvYVVVVCIVCSE9Pb3F7eno6PB555c5vslPnhefsn8LhMGbOnInRo0dj8ODBAE6eJ4fDAbfb3eK+Jp2nDtfdRXQu5efnY/v27fjoo4/O96F8pTrsFTstLQ12u73VJ5WVlZXIyJDX0/4mO3VeeM5Omj59OpYvX44PPvigRStwRkYGGhsbUV1d3eL+Jp2nDpvYDocDubm5KCwsbL4tHA6jsLAQeXl55/HIOq6cnBxkZGS0OGc+nw/r16//Rp0zy7Iwffp0LF26FO+//z5yclpuypCbm4uYmJgW56mkpASlpaXmnKfz/emdZvHixZbT6bQWLlxo7dy507r77rstt9tteTye831o501NTY21efNma/PmzRYA66mnnrI2b95sHTx40LIsy3r88cctt9ttvfXWW9bWrVutm266ycrJybEaGhrO85F/daZNm2a5XC5r1apVVkVFRfNPfX19833uvfdeKzs723r//fetjRs3Wnl5eVZeXt55POpzq0MntmVZ1nPPPWdlZ2dbDofDGjFihLVu3brzfUjn1QcffGABaPUzdepUy7JOlrwefPBBKz093XI6nda4ceOskpKS83vQX7FI5weAtWDBgub7NDQ0WPfdd5+VkpJixcfHWzfffLNVUVFx/g76HGPbJpGBOuzf2ER05pjYRAZiYhMZiIlNZCAmNpGBmNhEBmJiExmIiU1kICY2kYGY2EQGYmITGYiJTWSg/wXFFXX6VgY1IQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(W_1)\n",
    "plt.show()\n",
    "plt.imshow(W_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, hidden_dim=50, learning_rate=0.01, epochs=1000):\n",
    "    input_dim = X.shape[1]  # 27\n",
    "    output_dim = y.shape[1]  # Also 27, for multi-class classification\n",
    "    \n",
    "    # Initialize parameters\n",
    "    params = initialize_parameters(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        A2, cache = forward_pass(X, params)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(y, A2)\n",
    "        \n",
    "        # Backpropagation\n",
    "        grads = backward_pass(X, y, cache, params)\n",
    "        \n",
    "        # Update parameters\n",
    "        params = update_parameters(params, grads,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
